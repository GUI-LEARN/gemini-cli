# æ›¿æ¢Geminiå¤§æ¨¡å‹å¯è¡Œæ€§åˆ†ææŠ¥å‘Š

## é¡¹ç›®æ¶æ„è¯„ä¼°

### âœ… ä¼˜ç§€çš„æŠ½è±¡è®¾è®¡
- **ContentGeneratoræ¥å£** å®Œç¾æŠ½è±¡äº†æ‰€æœ‰å¤§æ¨¡å‹è°ƒç”¨
- **è®¤è¯æ¨¡å—åŒ–** æ”¯æŒå¤šç§è®¤è¯æ–¹å¼ï¼ˆAPI Keyã€OAuthã€Vertex AIï¼‰
- **é…ç½®çµæ´»** é€šè¿‡ç¯å¢ƒå˜é‡å’Œé…ç½®æ–‡ä»¶ç®¡ç†

### ğŸ” å…³é”®é›†æˆç‚¹

## æ›¿æ¢æ–¹æ¡ˆè®¾è®¡

### æ–¹æ¡ˆ1: OpenAI GPTé›†æˆ
```typescript
// æ–°å¢æ–‡ä»¶: packages/core/src/core/openaiContentGenerator.ts
import OpenAI from 'openai';

export class OpenAIContentGenerator implements ContentGenerator {
  private client: OpenAI;
  
  constructor(config: ContentGeneratorConfig) {
    this.client = new OpenAI({
      apiKey: config.apiKey,
      baseURL: config.baseURL || 'https://api.openai.com/v1'
    });
  }
  
  async generateContent(request: GenerateContentParameters): Promise<GenerateContentResponse> {
    const response = await this.client.chat.completions.create({
      model: request.model || 'gpt-4-turbo',
      messages: this.convertToOpenAIMessages(request.contents),
      tools: request.tools?.map(t => this.convertToOpenAITool(t))
    });
    
    return this.convertFromOpenAIResponse(response);
  }
}
```

### æ–¹æ¡ˆ2: Claudeé›†æˆ
```typescript
// æ–°å¢æ–‡ä»¶: packages/core/src/core/anthropicContentGenerator.ts
import Anthropic from '@anthropic-ai/sdk';

export class AnthropicContentGenerator implements ContentGenerator {
  private client: Anthropic;
  
  constructor(config: ContentGeneratorConfig) {
    this.client = new Anthropic({
      apiKey: config.apiKey
    });
  }
  
  async generateContent(request: GenerateContentParameters): Promise<GenerateContentResponse> {
    const response = await this.client.messages.create({
      model: request.model || 'claude-3-5-sonnet-20241022',
      max_tokens: 8192,
      messages: this.convertToAnthropicMessages(request.contents)
    });
    
    return this.convertFromAnthropicResponse(response);
  }
}
```

### æ–¹æ¡ˆ3: æœ¬åœ°æ¨¡å‹é›†æˆ
```typescript
// æ–°å¢æ–‡ä»¶: packages/core/src/core/localModelContentGenerator.ts
export class LocalModelContentGenerator implements ContentGenerator {
  private baseURL: string;
  
  constructor(config: ContentGeneratorConfig) {
    this.baseURL = config.baseURL || 'http://localhost:11434/v1';
  }
  
  async generateContent(request: GenerateContentParameters): Promise<GenerateContentResponse> {
    const response = await fetch(`${this.baseURL}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${request.apiKey || 'ollama'}`
      },
      body: JSON.stringify({
        model: request.model || 'llama2',
        messages: this.convertToOpenAIMessages(request.contents)
      })
    });
    
    return response.json();
  }
}
```

## å…·ä½“å®æ–½æ­¥éª¤

### ç¬¬ä¸€æ­¥ï¼šæ·»åŠ æ–°è®¤è¯ç±»å‹
```typescript
// packages/core/src/config/config.ts
export enum AuthType {
  LOGIN_WITH_GOOGLE = 'oauth-personal',
  USE_GEMINI = 'gemini-api-key',
  USE_VERTEX_AI = 'vertex-ai',
  USE_OPENAI = 'openai-api-key',      // æ–°å¢
  USE_ANTHROPIC = 'anthropic-api-key', // æ–°å¢
  USE_LOCAL = 'local-model',          // æ–°å¢
  CLOUD_SHELL = 'cloud-shell'
}
```

### ç¬¬äºŒæ­¥ï¼šä¿®æ”¹ContentGeneratorå·¥å‚å‡½æ•°
```typescript
// packages/core/src/core/contentGenerator.ts
export function createContentGenerator(config: ContentGeneratorConfig): ContentGenerator {
  switch (config.authType) {
    case AuthType.USE_OPENAI:
      return new OpenAIContentGenerator(config);
    case AuthType.USE_ANTHROPIC:
      return new AnthropicContentGenerator(config);
    case AuthType.USE_LOCAL:
      return new LocalModelContentGenerator(config);
    default:
      return new GeminiContentGenerator(config);
  }
}
```

### ç¬¬ä¸‰æ­¥ï¼šæ›´æ–°ç¯å¢ƒå˜é‡éªŒè¯
```typescript
// packages/cli/src/config/auth.ts
const AUTH_REQUIREMENTS: Record<AuthType, string[]> = {
  [AuthType.USE_OPENAI]: ['OPENAI_API_KEY'],
  [AuthType.USE_ANTHROPIC]: ['ANTHROPIC_API_KEY'],
  [AuthType.USE_LOCAL]: ['LOCAL_MODEL_URL'] // å¯é€‰
};
```

### ç¬¬å››æ­¥ï¼šæ›´æ–°æ¨¡å‹é…ç½®
```typescript
// packages/core/src/config/models.ts
export const MODEL_CONFIGS = {
  openai: {
    'gpt-4-turbo': { maxTokens: 128000 },
    'gpt-3.5-turbo': { maxTokens: 16384 }
  },
  anthropic: {
    'claude-3-5-sonnet-20241022': { maxTokens: 200000 },
    'claude-3-opus-20240229': { maxTokens: 200000 }
  },
  local: {
    'llama2': { maxTokens: 4096 },
    'mistral': { maxTokens: 8192 }
  }
};
```

## å…¼å®¹æ€§åˆ†æ

### âœ… å®Œå…¨å…¼å®¹çš„åŠŸèƒ½
- **æ–‡ä»¶ç³»ç»Ÿæ“ä½œ** (ls, read, write, edit)
- **ä»£ç æ‰§è¡Œ** (shellå‘½ä»¤)
- **å·¥å…·è°ƒç”¨æ¡†æ¶** (MCPæœåŠ¡å™¨)
- **UIç•Œé¢** (React/Ink)
- **é…ç½®ç®¡ç†** (ç¯å¢ƒå˜é‡ã€é…ç½®æ–‡ä»¶)

### âš ï¸ éœ€è¦é€‚é…çš„åŠŸèƒ½
- **Tokenè®¡ç®—** - ä¸åŒæ¨¡å‹çš„tokenè®¡ç®—æ–¹å¼ä¸åŒ
- **å·¥å…·è°ƒç”¨æ ¼å¼** - éœ€è¦è½¬æ¢ä¸åŒAPIçš„å·¥å…·è°ƒç”¨æ ¼å¼
- **æµå¼å“åº”** - å„APIçš„æµå¼å“åº”æ ¼å¼ä¸åŒ
- **é”™è¯¯å¤„ç†** - å„APIçš„é”™è¯¯ç å’Œæ ¼å¼ä¸åŒ

## å®æ–½å·¥ä½œé‡è¯„ä¼°

### ğŸŸ¢ ä½å¤æ‚åº¦ (1-2å¤©)
- **åŸºç¡€APIæ›¿æ¢** - æ ¸å¿ƒå¯¹è¯åŠŸèƒ½
- **ç¯å¢ƒå˜é‡é…ç½®** - æ–°å¢è®¤è¯æ–¹å¼

### ğŸŸ¡ ä¸­ç­‰å¤æ‚åº¦ (3-5å¤©)
- **å·¥å…·è°ƒç”¨é€‚é…** - è½¬æ¢ä¸åŒAPIçš„å·¥å…·æ ¼å¼
- **Tokenè®¡ç®—ä¼˜åŒ–** - é€‚é…å„æ¨¡å‹çš„tokené™åˆ¶
- **æµå¼å“åº”å¤„ç†** - ç»Ÿä¸€æµå¼å“åº”æ¥å£

### ğŸ”´ é«˜å¤æ‚åº¦ (1-2å‘¨)
- **å®Œæ•´æµ‹è¯•è¦†ç›–** - ç¡®ä¿æ‰€æœ‰åŠŸèƒ½æ­£å¸¸
- **æ€§èƒ½ä¼˜åŒ–** - å“åº”é€Ÿåº¦å’Œç¨³å®šæ€§è°ƒä¼˜
- **æ–‡æ¡£æ›´æ–°** - æ›´æ–°æ‰€æœ‰ç›¸å…³æ–‡æ¡£

## æ¨èå®æ–½é¡ºåº

1. **é˜¶æ®µ1**: é›†æˆOpenAI GPT (æœ€ç›¸ä¼¼API)
2. **é˜¶æ®µ2**: é›†æˆAnthropic Claude
3. **é˜¶æ®µ3**: é›†æˆæœ¬åœ°æ¨¡å‹ (Ollama/Llama.cpp)
4. **é˜¶æ®µ4**: æ”¯æŒå¤šæ¨¡å‹åˆ‡æ¢

## ç»“è®º

**âœ… é«˜åº¦å¯è¡Œ** - é¡¹ç›®æ¶æ„è®¾è®¡ä¼˜ç§€ï¼Œæ›¿æ¢æˆæœ¬ç›¸å¯¹è¾ƒä½ã€‚

**å…³é”®ä¼˜åŠ¿**:
- æ¸…æ™°çš„æ¥å£æŠ½è±¡
- æ¨¡å—åŒ–è®¤è¯è®¾è®¡
- çµæ´»çš„é…ç½®ç®¡ç†
- å®Œæ•´çš„æµ‹è¯•è¦†ç›–

**é¢„è®¡å·¥ä½œé‡**: 2-4å¤©å¯å®ç°åŸºç¡€æ›¿æ¢ï¼Œ1-2å‘¨å®Œæˆå®Œæ•´é›†æˆã€‚